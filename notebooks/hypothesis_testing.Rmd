---
title: "Hypothesis testing on MovieLens dataset"
date: 14/07/2018
author: José Benardi de Souza Nunes
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<br></br>

# Introduction

</br>

> This report is an analysis on the dataset movielens which can be found in full [here](https://grouplens.org/datasets/movielens/latest/). The code, data, a description of the variables used in this report and another report employing Confindence Intervals on the same dataset can be found in the [original repository](https://github.com/Benardi/movielens_analysis/)

</br>

***

</br>

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
library(here)
library(coin)
library(resample)
library(tidyverse)


theme_set(theme_bw())
```

# Data Overview 

</br>

## Loading and filtering data

```{r, warning=FALSE}
readr::read_csv(here::here("data/movies.csv"),
                progress = FALSE,
                col_types = cols(
                      movieId = col_integer(),
                      title = col_character(),
                      genres = col_character()
                    )) %>% 
  group_by(movieId) %>%
  mutate(year = as.numeric(sub("\\).*", "",sub(".*\\(", "", title))),
         num_genres = length(as.list(strsplit(genres,'|',fixed = TRUE))[[1]]),
         homogeneous = num_genres == 1, # Deriving homogeneity
         xx_century = year <= 2000
         ) %>%  
  na.omit() %>%
  ungroup() -> movies

readr::read_csv(here::here("data/ratings.csv"),
                progress = FALSE,
                col_types = cols(
                userId = col_integer(),
                movieId = col_integer(),
                rating = col_double(),
                timestamp = col_integer()
                )) %>%
  na.omit() -> ratings
```

```{r}
dplyr::inner_join(
  movies,
  ratings,
  by="movieId") -> data


data %>%
  group_by(movieId) %>%
  summarise(median_rating = median(rating), # Deriving whether a movies is well rated
            well_rated = median_rating > 3.5) -> summarised


dplyr::inner_join(
  summarised,
  data,
  by="movieId") -> data

data %>%
  glimpse()
```

```{r}
movies %>%
  filter(title == "Hamlet (2000)")

data %>%
  filter(movieId != 3598) -> data
```

* Looks like Hamlet was included twice. As Hamlet is clearly a Drama we're gonna remove the entries that say otherwise.

<br>

## Checking overall data consistency

```{r}
data %>%
  group_by(movieId) %>%
  slice(1) %>%
  ggplot(aes(year)) +
  geom_bar() +
  labs(x="Movie Year",
       y="Absolute Frequency")
```

* There's a whole lot of movies from the 2000's.
* There's movies going as far as the first decade of the 1900's.

```{r}
data %>%
  ggplot(aes(num_genres)) +
  geom_bar() +
  labs(x="Number of Genres",
       y="Absolute Frequency")
```

* Most movies have 2 or 3 genres.

```{r}
data %>%
  ggplot(aes(rating,y=..prop..)) +
  geom_bar() +
  labs(x="Movie Rating", 
       y="Relative Frequency")
```

* There's a lot of generous reviews, with 4 stars composing almost 30% of the ratings. 

<br>

## Conclusion

<br>

* Anomalous data filtered (i.e. Hamlet).

* No further data found violating expected range or categories.

<br>

***

<br>

# Is the movie well rated

<br>

* Where our analysis regards impact of genre we shall consider only the movies homogeneous in terms of genre, we do so to have a clearer picture of the effect of the different genres.
* Movies are considered well rated when they have been rated above 2.5 stars in terms of median. 

## Is there a difference in the proportion of well rated rated movies when we compare movies from XX and XXI century?

<br>

* We will use as estimator the unpaired difference of the proportion of well rated (TRUE - FALSE):
    + **The proportion of well rated of movies from the XX century minus the proportion of well rated of movies from the XXI century**.
    
Agora vejamos o quão frequente seria encontrarmos uma diferença do tamanho que encontramos se não houvesse associação nenhuma entre qual é o episódio e qual é a avaliação que ele recebe. A situação onde não existe associação é a hipótese nula. Se a diferença que observamos em nossa amostra acontece facilmente na hipótese nula, isso significa que não temos evidência forte de associação: o que observamos acontece também quando não há associação. 

No caso onde a diferença que observamos é improvável na hipótese nula, então observamos algo que é indicativo de associação. Repare que é uma dupla negação: se não acontece associação como a que vimos na amostra na situação onde não há associação, então temos evidência de que há associação. 

## Let's use the resample package

```{r}
permutationTest2(data = data,
                 R=5000,
                 statistic = prop.table(table(well_rated))[2],
                 treatment = xx_century)
```

<br>

* In accordance to our previous results employing a **Confindence Interval** our results using a _two tailed permutation test_ do suggest that there's in fact an association and consequently the null hypothesis should be rejected.
    +  The _two tailed permutation test_ rendered a **PValue** (0.00039992) far below the chosen **alpha** (0.05) which indicates that an effect is indeed present, therefore at a confidence level of 95% we can say that there's a statistically significant difference between the proportion of well rated movies of movies from the XX century and movies from the XXI century.    

<br>

## Let's use the coin package

```{r}
independence_test(well_rated ~ xx_century, 
                  data = data)
```

* Once again we have results that agree with our previous results employing a **Confindence Interval**.
    +  The _two tailed permutation test_ rendered a **PValue** (2.2e-16) far below the chosen **alpha** (0.05) which indicates that an effect is indeed present, therefore at a confidence level of 95% we can say that there's a statistically significant difference between the proportion of well rated movies of movies from the XX century and movies from the XXI century.  
